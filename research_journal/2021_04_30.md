# 2021-04-30

## Insert the data into a local database

Finally, I managed to insert the data into a local database using PostgreSQL. This is the result of a couple of days of work, since the topic was not really clear in my mind.Let's write a brief recap.

### `PostgreSQL`, GUI and CLI clients.

First, with `homebrew` I had previously installed `PostgreSQL` using `brew install PostgreSQL`. This does *not* install any GUI client, but the command-line interface (CLI) is enough of itself to deal with the whole data management situation.

There are two popular GUIs that are used to deal with this. The first is [PostgresApp](https://github.com/PostgresApp/PostgresApp), which can be installed using `brew install --cask postgres`: it is easy to get confused! PostgresApp not only allows to manage the servers and create new databases but it comes also with `PostgreSQL`. Because of this, it is generally heavy -- just less than 900MB. This is way I did not choose to use that. For this reason, whenever I am writing `Postgres` I do not mean this application, but the actual `postgres` binary that comes shipped with the installation of `PostgreSQL`.

The people at `PostgreSQL` created another GUI client to manage databases: `pgAdmin` (`brew install --cask pgadmin4`). `pgAdmin` is still heavy: a bit less than 500MB, but is also useful for writing queries. The main purpose I used it, as I shall describe with more detail later, is to copy the `.csv` files into the local databse I created.

### PostgreSQL installation

I do not recall any of this, unfortunately. When re-installing PostgreSQL using `homebrew` no startup message appears. However, I recall this installation creates a new superuser, `postgres`.

### Using PostgreSQL to create a new database cluster/server 

`PostgreSQL` installs some CLI binaries to deal with data. The first is `postgres`, which is actually not used: as claimed in the official documentation, the syntax can become quite complicated very easily. For this reason, there is a wrapper for that: `pg_ctl`. With this, we can create servers, start and stop them.

In my `zsh` configuration file, `.zshenv`, I have defined the environment variable `PGDATA='/usr/local/var/postgres` as the directory where I have my first and only server. In this way, when I `pg_ctl start` it automatically launches this server. Otherwise, one would have to specify the `-D` flag. One remark: please do not call your server `postgres` as this may give rise to some confusion. Something else, such as `pgdata`, works better.

### Using `psql` to create a new database inside a cluster/server 

After this, I created a database called `tesi` to contain the data for the thesis. This is simply achieved, but there is one more thing required to know. `pg_ctl` is used to manage servers: to connect to them, one needs to use `psql`. The workflow is a bit odd, though: after starting the server with `pg_ctl start`, I `psql tesi`. I specify `tesi`, but any other database you have in the server works. Actually, every server comes with a default `postgres` database to toy around with. This is needed because otherwise `psql` will default to either the owner of the database folder or the current user -- that I did not figure out.

After this, one can write its queries within the `psql` prompt, but while manageable it can be tedious. Queries can also be run using the `-c` flag of `psql` and can be imported from a text file, but `pgAdmin` is more useful in this sense.

### Importing csv in a PosgreSQL table

This is where `pgAdmin` comes into play and actually may be the only time it is needed. Its purpose is to copy from a `.csv` file the data into a new table in the databse in the local server (that is a mouthful). The syntax is relatively simple. First, you need to create a database:

```
CREATE DATABASE tesi
```

Before starting to copy the data into the table, we need to check if there are any `datetime` columns in the data. `PostgreSQL` parses automatically the data in the `ISO YYYY/mm/dd` format. If the data in your `.csv` is different, you will need to adjust the `datestyle`:

```
SET datestyle TO iso, dmy;
```

Then we create the table and specify all columns needed.

```
CREATE TABLE IF NOT EXISTS bikes (
	bici INT,
	tipo_bici VARCHAR(20),
	cliente_anonimizzato INT,
	data_riferimento_prelievo DATE,
	data_prelievo TIMESTAMP,
	numero_stazione_prelievo INT,
	nome_stazione_prelievo TEXT,
	slot_prelievo SMALLINT,
	data_riferimento_restituzione DATE,
	data_restituzione TIMESTAMP,
	numero_stazione_restituzione INT,
	nome_stazione_restituzione TEXT,
	slot_restituzione SMALLINT,
	durata VARCHAR(10),
	distanza_totale REAL,
	co2_evitata REAL,
	calorie_consumate REAL,
	penalità CHAR(2)
);
```
Then add another query to copy the content of the file:

```
COPY bikes(
	bici,
	tipo_bici,
	cliente_anonimizzato,
	data_riferimento_prelievo,
	data_prelievo,
	numero_stazione_prelievo,
	nome_stazione_prelievo,
	slot_prelievo,
	data_riferimento_restituzione,
	data_restituzione,
	numero_stazione_restituzione,
	nome_stazione_restituzione,
	slot_restituzione,
	durata,
	distanza_totale,
	co2_evitata,
	calorie_consumate,
	penalità
)
FROM '/Users/luca/tesi/data/2019q3.csv'
DELIMITER ','
CSV HEADER;
```

### Final remark

It would be better to get rid of the unneded columns before uploading it to the database.
